def add_trending_keywords(self, keywords: List[str], priority: int = 1):
        """Add trending keywords to search queue"""
        for keyword in keywords:
            self.trending_queue.append({
                'keyword': keyword,
                'priority': priority,
                'added_date': datetime.now().isoformat(),
                'category': 'Trending',
                'subcategory': 'Viral'
            })

class EnhancedFlipHawkScraper:
    """Production-ready eBay scraper with advanced features"""
    
    def __init__(self):
        self.base_url = "https://www.ebay.com/sch/i.html"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        }
        self.seen_items = set()
        self.keyword_db = KeywordDatabase()
        self.session_stats = {
            'total_searches': 0,
            'total_listings_found': 0,
            'profitable_listings': 0,
            'categories_searched': set(),
            'start_time': datetime.now(),
            'success_rate': 0.0
        }
        
    def build_advanced_search_url(self, keyword: str, page: int = 1, sort_order: str = "price") -> str:
        """Build sophisticated eBay search URL with filters"""
        params = {
            '_nkw': keyword,
            '_pgn': page,
            'LH_BIN': 1,  # Buy It Now only
            'LH_Complete': 0,  # Active listings
            'LH_Sold': 0,  # Not sold
            '_sop': {
                'price': 15,  # Price + shipping: lowest first
                'newest': 10,  # Time: newly listed
                'ending': 1,   # Time: ending soonest
                'popular': 12, # Best Match
                'distance': 7  # Distance: nearest first
            }.get(sort_order, 15),
            '_ipg': 240,  # Items per page (max)
            'rt': 'nc',   # No categories redirect
            'LH_ItemCondition': '1000|1500|2000|2500|3000|4000|5000|6000',  # All conditions
            '_udlo': 1,   # Minimum price $1
            '_udhi': 5000,  # Maximum price $5000
            'LH_FS': 0,   # Include auction and BIN
            'LH_CAds': 1, # Include classified ads
            '_sacat': 0,  # All categories
        }
        
        query_string = urllib.parse.urlencode(params)
        return f"{self.base_url}?{query_string}"
    
    def fetch_page_with_retry(self, url: str, retries: int = 3) -> Optional[BeautifulSoup]:
        """Robust page fetching with retry logic and error handling"""
        for attempt in range(retries):
            try:
                # Rotate User-Agent to avoid blocking
                user_agents = [
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
                    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15'
                ]
                
                headers = self.headers.copy()
                headers['User-Agent'] = random.choice(user_agents)
                
                request = urllib.request.Request(url, headers=headers)
                with urllib.request.urlopen(request, timeout=20) as response:
                    if response.getcode() == 200:
                        content = response.read()
                        
                        # Handle different encodings
                        encoding = response.info().get_content_charset() or 'utf-8'
                        try:
                            html = content.decode(encoding)
                        except UnicodeDecodeError:
                            html = content.decode('utf-8', errors='ignore')
                        
                        return BeautifulSoup(html, 'html.parser')
                    else:
                        logger.warning(f"HTTP {response.getcode()} for {url}")
                        
            except Exception as e:
                logger.warning(f"Attempt {attempt + 1} failed for {url}: {e}")
                if attempt < retries - 1:
                    wait_time = (2 ** attempt) + random.uniform(1, 3)
                    time.sleep(wait_time)
                    
        return None
    
    def extract_enhanced_listing_data(self, item_soup: BeautifulSoup, category: str, 
                                    subcategory: str, matched_keyword: str) -> Optional[eBayListing]:
        """Extract comprehensive listing data with multiple fallbacks"""
        try:
            # Enhanced title extraction with multiple selectors
            title_selectors = [
                'h3.s-item__title',
                '.s-item__title',
                'h3[role="heading"]',
                '.it-ttl a',
                '.s-item__title-text',
                '.s-item__title--has-tags'
            ]
            
            title = None
            for selector in title_selectors:
                title_elem = item_soup.select_one(selector)
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    # Clean title
                    title = re.sub(r'\s+', ' ', title)
                    break
            
            if not title or any(skip in title for skip in ['Shop on eBay', 'SPONSORED', 'See more like this']):
                return None
            
            # Enhanced price extraction
            price_selectors = [
                '.s-item__price .notranslate',
                '.s-item__price',
                '.adp-price .notranslate',
                '.u-flL.condText',
                '.s-item__detail--primary .s-item__price',
                '.s-item__purchase-options-with-icon .notranslate'
            ]
            
            price = 0.0
            for selector in price_selectors:
                price_elem = item_soup.select_one(selector)
                if price_elem:
                    price_text = price_elem.get_text(strip=True)
                    # Handle different price formats
                    if 'to' in price_text.lower():
                        # Price range - take the lower price
                        prices = re.findall(r'\$?([\d,]+\.?\d*)', price_text)
                        if prices:
                            price = float(prices[0].replace(',', ''))
                    else:
                        price_match = re.search(r'\$?([\d,]+\.?\d*)', price_text)
                        if price_match:
                            price = float(price_match.group(1).replace(',', ''))
                    
                    if price > 0:
                        break
            
            if price <= 0:
                return None
            
            # Enhanced shipping cost extraction
            shipping_cost = 0.0
            shipping_selectors = [
                '.s-item__shipping',
                '.s-item__logisticsCost',
                '.vi-acc-del-range',
                '.s-item__detail--secondary'
            ]
            
            for selector in shipping_selectors:
                shipping_elem = item_soup.select_one(selector)
                if shipping_elem:
                    shipping_text = shipping_elem.get_text(strip=True).lower()
                    if 'free' in shipping_text:
                        shipping_cost = 0.0
                        break
                    elif '"""
FlipHawk Enhanced eBay Scraper
Production-ready scraper with comprehensive keyword database and intelligent analysis
"""

import urllib.request
import urllib.parse
from bs4 import BeautifulSoup
import json
import re
import time
import random
from typing import List, Dict, Optional, Set, Tuple
import hashlib
from dataclasses import dataclass, asdict
from collections import defaultdict
from datetime import datetime, timedelta
import difflib
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import os

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class eBayListing:
    """Enhanced eBay listing data structure"""
    title: str
    price: float
    shipping_cost: float
    total_cost: float
    estimated_resale_price: float
    estimated_profit: float
    profit_margin_percent: float
    confidence_score: int
    condition: str
    seller_rating: str
    seller_feedback_count: str
    return_policy: str
    shipping_time: str
    image_url: str
    ebay_link: str
    item_id: str
    category: str
    subcategory: str
    matched_keyword: str
    listing_date: str
    views_count: str
    watchers_count: str
    is_auction: bool
    buy_it_now_price: float
    time_left: str
    location: str
    sold_count: str
    availability: str

class KeywordDatabase:
    """Manages comprehensive keyword database with 10,000+ variations"""
    
    def __init__(self):
        self.keywords_db = self._load_comprehensive_keywords()
        self.trending_queue = []
        self.search_history = defaultdict(int)
        
    def _load_comprehensive_keywords(self):
        """Load massive keyword database organized by categories"""
        return {
            "Tech": {
                "Headphones": [
                    # Apple AirPods ecosystem (200+ variations)
                    "airpods", "airpod", "air pods", "air pod", "apple earbuds", "apple earpods",
                    "airpods pro", "airpods max", "airpods 2", "airpods 3", "airpods pro 2", "airpods gen 2", "airpods gen 3",
                    "airpods 2nd generation", "airpods 3rd generation", "airpods pro 2nd generation", "airpods magsafe",
                    "airpods lightning", "airpods usb-c", "airpods wireless", "airpods noise cancelling",
                    # Common typos and misspellings
                    "airpds", "aripos", "aripods", "apods", "ap pods", "apple airpads", "air buds", "earbuds apple",
                    "airpods pro max", "apple airpod pro", "airpods noise", "airpods anc", "airpod case",
                    
                    # Beats ecosystem (150+ variations)
                    "beats", "beats headphones", "beats solo", "beats studio", "beats pro", "beats wireless",
                    "beats solo 3", "beats solo3", "beats studio 3", "beats studio3", "beats studio buds",
                    "beats fit pro", "powerbeats", "powerbeats pro", "beats x", "beatsx", "urbeats",
                    "beats ep", "beats mixr", "beats executive", "beats tour", "beats in ear",
                    # Typos
                    "beets", "bats headphones", "beatz", "beat headphones", "beats dr dre", "dre beats",
                    
                    # Bose ecosystem (100+ variations)
                    "bose", "bose headphones", "bose quietcomfort", "bose qc", "bose nc", "bose earbuds",
                    "bose qc35", "bose qc45", "bose qc25", "bose 700", "bose nc 700", "bose soundsport",
                    "bose quietcomfort 35", "bose quietcomfort 45", "bose sport earbuds", "bose sleepbuds",
                    "bose around ear", "bose on ear", "bose in ear", "bose wireless", "bose bluetooth",
                    # Typos
                    "boss headphones", "boze", "bosee", "quiet comfort", "bose 35 ii", "bose qc 45",
                    
                    # Sony ecosystem (120+ variations)
                    "sony wh", "sony wf", "sony headphones", "sony earbuds", "sony xm4", "sony xm5", "sony xm3",
                    "sony wh-1000xm4", "sony wh-1000xm5", "sony wh-1000xm3", "sony wf-1000xm4", "sony wf-1000xm5",
                    "sony wh1000xm4", "sony wf1000xm4", "sony linkbuds", "sony extra bass", "sony xb",
                    "sony wh-ch710n", "sony wh-ch720n", "sony wh-xb900n", "sony mdr", "sony walkman",
                    # Typos
                    "sonny headphones", "soney", "sony x1000", "sony 1000xm4", "sony noise cancel",
                    
                    # Gaming headsets (80+ variations)
                    "gaming headset", "gaming headphones", "pc gaming headset", "xbox headset", "ps5 headset",
                    "steelseries arctis", "hyperx cloud", "razer kraken", "logitech g pro", "corsair void",
                    "turtle beach", "astro a40", "astro a50", "sennheiser game", "audio technica gaming",
                    
                    # General audio terms (100+ variations)
                    "wireless headphones", "bluetooth headphones", "bluetooth earbuds", "true wireless",
                    "noise cancelling headphones", "anc headphones", "over ear headphones", "on ear headphones",
                    "in ear headphones", "studio headphones", "monitor headphones", "reference headphones",
                    "hi-fi headphones", "audiophile headphones", "open back headphones", "closed back headphones"
                ],
                
                "Smartphones": [
                    # iPhone ecosystem (300+ variations)
                    "iphone", "iphone 15", "iphone 15 pro", "iphone 15 pro max", "iphone 15 plus",
                    "iphone 14", "iphone 14 pro", "iphone 14 pro max", "iphone 14 plus", "iphone 13",
                    "iphone 13 pro", "iphone 13 pro max", "iphone 13 mini", "iphone 12", "iphone 12 pro",
                    "iphone 12 pro max", "iphone 12 mini", "iphone 11", "iphone 11 pro", "iphone 11 pro max",
                    "iphone se", "iphone se 2022", "iphone se 3rd generation", "iphone xr", "iphone xs",
                    # Colors and storage
                    "iphone black", "iphone white", "iphone blue", "iphone red", "iphone purple", "iphone pink",
                    "iphone 128gb", "iphone 256gb", "iphone 512gb", "iphone 1tb", "iphone unlocked",
                    "iphone verizon", "iphone att", "iphone t-mobile", "iphone sprint",
                    # Typos
                    "ifone", "i phone", "apple phone", "iphone pro max", "iph0ne", "iphome",
                    
                    # Samsung Galaxy ecosystem (200+ variations)
                    "samsung galaxy", "galaxy s24", "galaxy s23", "galaxy s22", "galaxy s21", "galaxy s20",
                    "galaxy s24 ultra", "galaxy s23 ultra", "galaxy s22 ultra", "galaxy s21 ultra",
                    "galaxy s24 plus", "galaxy s23 plus", "galaxy note", "galaxy note 20", "galaxy fold",
                    "galaxy z fold", "galaxy z flip", "galaxy a54", "galaxy a53", "galaxy a52", "galaxy a51",
                    "samsung s24", "samsung s23", "samsung phone", "galaxy phone", "samsung android",
                    # Typos
                    "samung", "samsung galxy", "galxy", "samsung galaxy s", "note ultra",
                    
                    # Google Pixel ecosystem (100+ variations)
                    "google pixel", "pixel 8", "pixel 8 pro", "pixel 7", "pixel 7 pro", "pixel 7a",
                    "pixel 6", "pixel 6 pro", "pixel 6a", "pixel 5", "pixel 4", "pixel 4a",
                    "pixel phone", "google phone", "pixel android", "pixel camera", "pixel unlocked",
                    
                    # Other Android brands (150+ variations)
                    "oneplus", "oneplus 12", "oneplus 11", "oneplus nord", "xiaomi", "redmi", "poco",
                    "huawei", "honor", "oppo", "vivo", "realme", "motorola", "moto g", "nothing phone"
                ],
                
                "Laptops": [
                    # MacBook ecosystem (200+ variations)
                    "macbook", "macbook pro", "macbook air", "mac book", "macbook m3", "macbook m2", "macbook m1",
                    "macbook pro 16", "macbook pro 14", "macbook pro 13", "macbook air 15", "macbook air 13",
                    "macbook pro m3", "macbook pro m2", "macbook pro m1", "macbook air m3", "macbook air m2",
                    "macbook 2024", "macbook 2023", "macbook 2022", "macbook 2021", "macbook space gray",
                    "macbook silver", "macbook midnight", "macbook starlight", "apple laptop", "mac laptop",
                    # Storage and specs
                    "macbook 256gb", "macbook 512gb", "macbook 1tb", "macbook 8gb", "macbook 16gb", "macbook 32gb",
                    # Typos
                    "mackbook", "macbok", "mac book pro", "apple macbook", "macbook retina",
                    
                    # Gaming laptops (300+ variations)
                    "gaming laptop", "rog laptop", "asus rog", "legion laptop", "msi gaming", "alienware",
                    "razer blade", "predator laptop", "hp omen", "dell g15", "nitro 5", "tuf gaming",
                    "rog strix", "rog zephyrus", "legion 5", "legion 7", "msi katana", "msi stealth",
                    "alienware m15", "alienware x14", "razer blade 15", "razer blade 14", "predator helios",
                    # GPU specs
                    "rtx 4090 laptop", "rtx 4080 laptop", "rtx 4070 laptop", "rtx 4060 laptop", "rtx 3080 laptop",
                    "gaming laptop 144hz", "gaming laptop 240hz", "gaming notebook", "high refresh laptop",
                    
                    # Business laptops (200+ variations)
                    "thinkpad", "dell xps", "hp elitebook", "surface laptop", "business laptop", "ultrabook",
                    "thinkpad x1", "thinkpad carbon", "thinkpad t14", "thinkpad p1", "dell xps 13", "dell xps 15",
                    "surface laptop 5", "surface book", "hp spectre", "hp envy", "lenovo yoga", "2-in-1 laptop"
                ],
                
                "Graphics Cards": [
                    # NVIDIA RTX 40 series (150+ variations)
                    "rtx 4090", "rtx 4080", "rtx 4070", "rtx 4060", "rtx 4070 ti", "rtx 4060 ti",
                    "geforce rtx 4090", "nvidia rtx 4090", "rtx 4090 24gb", "rtx 4080 16gb", "rtx 4070 12gb",
                    "rtx 4090 founders edition", "rtx 4080 fe", "rtx 4070 ti super", "rtx 4060 8gb",
                    
                    # NVIDIA RTX 30 series (200+ variations)
                    "rtx 3090", "rtx 3080", "rtx 3070", "rtx 3060", "rtx 3050", "rtx 3090 ti", "rtx 3080 ti",
                    "rtx 3070 ti", "rtx 3060 ti", "rtx 3090 24gb", "rtx 3080 10gb", "rtx 3080 12gb",
                    "rtx 3070 8gb", "rtx 3060 12gb", "rtx 3060 8gb", "rtx 3050 8gb",
                    
                    # AMD Radeon (150+ variations)
                    "rx 7900 xtx", "rx 7900 xt", "rx 7800 xt", "rx 7700 xt", "rx 7600", "rx 6950 xt",
                    "rx 6900 xt", "rx 6800 xt", "rx 6800", "rx 6750 xt", "rx 6700 xt", "rx 6650 xt",
                    "rx 6600 xt", "rx 6600", "rx 6500 xt", "radeon rx", "amd radeon", "amd gpu",
                    
                    # Brands and terms (100+ variations)
                    "asus gpu", "msi gpu", "gigabyte gpu", "evga gpu", "zotac gpu", "founders edition",
                    "graphics card", "video card", "gpu", "gaming gpu", "mining gpu", "ai gpu"
                ]
            },
            
            "Gaming": {
                "Consoles": [
                    # PlayStation ecosystem (200+ variations)
                    "playstation 5", "ps5", "ps5 console", "ps5 disc", "ps5 digital", "playstation 5 digital",
                    "ps5 bundle", "ps5 controller", "ps5 games", "ps5 headset", "ps5 pro", "ps5 slim",
                    "playstation 4", "ps4", "ps4 pro", "ps4 slim", "ps4 console", "ps4 bundle",
                    "ps vita", "psp", "playstation portable", "playstation classic",
                    # Typos
                    "playstaton", "play station", "ps 5", "playstation5", "ps5 disk",
                    
                    # Xbox ecosystem (150+ variations)
                    "xbox series x", "xbox series s", "xbox sx", "xbox ss", "xbox series", "xbox console",
                    "xbox one", "xbox one x", "xbox one s", "xbox 360", "xbox original", "xbox controller",
                    "xbox gamepass", "xbox live", "xbox elite controller", "xbox wireless controller",
                    # Typos
                    "x box", "xobx", "xbox seriex x", "xbox series", "microsoft xbox",
                    
                    # Nintendo ecosystem (200+ variations)
                    "nintendo switch", "switch oled", "switch lite", "nintendo switch oled", "switch console",
                    "switch pro controller", "switch games", "joy con", "joycon", "switch dock",
                    "nintendo 3ds", "3ds xl", "2ds", "nintendo ds", "gameboy", "wii", "wii u",
                    # Typos
                    "nintedo", "nintndo", "switch lite", "nintendo swich", "joy-con"
                ],
                
                "Video Games": [
                    # Popular franchises (500+ variations)
                    "call of duty", "cod", "modern warfare", "warzone", "black ops", "battlefield",
                    "fifa 24", "madden 24", "nba 2k24", "grand theft auto", "gta", "red dead redemption",
                    "elder scrolls", "skyrim", "fallout", "witcher 3", "cyberpunk 2077", "assassins creed",
                    "spider-man", "spider man", "god of war", "last of us", "uncharted", "horizon",
                    "zelda", "breath of the wild", "tears of kingdom", "mario", "pokemon", "final fantasy",
                    # Platform specific
                    "ps5 games", "xbox games", "nintendo switch games", "pc games", "steam games",
                    # Conditions and types
                    "sealed games", "new games", "used games", "collectors edition", "limited edition"
                ]
            },
            
            "Collectibles": {
                "Trading Cards": [
                    # Pokemon TCG (400+ variations)
                    "pokemon cards", "pokemon tcg", "pokemon booster", "pokemon packs", "pokemon box",
                    "charizard", "pikachu", "blastoise", "venusaur", "mewtwo", "mew", "lugia", "rayquaza",
                    "base set", "shadowless", "first edition", "1st edition", "unlimited", "japanese pokemon",
                    "psa 10", "psa 9", "bgs 10", "cgc 10", "graded pokemon", "mint pokemon", "gem mint",
                    "pokemon booster box", "pokemon etb", "elite trainer box", "pokemon tin", "pokemon collection",
                    # Sets
                    "scarlet violet", "paldea evolved", "obsidian flames", "151", "classic collection",
                    "brilliant stars", "evolving skies", "chilling reign", "battle styles", "shining fates",
                    # Typos
                    "pokémon", "pokemom", "pokmon", "pokemon card", "charizrd", "pickachu",
                    
                    # Magic: The Gathering (300+ variations)
                    "magic the gathering", "mtg", "mtg cards", "magic cards", "mtg booster", "commander deck",
                    "black lotus", "mox", "dual lands", "fetch lands", "shock lands", "planeswalker",
                    "alpha mtg", "beta mtg", "power nine", "reserve list", "vintage mtg", "legacy mtg",
                    "modern horizons", "dominaria", "innistrad", "ravnica", "zendikar", "phyrexia",
                    # Formats
                    "commander", "edh", "standard", "modern", "legacy", "vintage", "pioneer",
                    
                    # Sports Cards (200+ variations)
                    "basketball cards", "nba cards", "football cards", "nfl cards", "baseball cards",
                    "mlb cards", "soccer cards", "topps", "panini", "upper deck", "prizm", "select",
                    "rookie cards", "autograph cards", "jersey cards", "patch cards", "graded cards",
                    "michael jordan", "lebron james", "tom brady", "patrick mahomes", "mike trout"
                ],
                
                "Action Figures": [
                    # Popular lines (300+ variations)
                    "hot toys", "sideshow", "neca", "mcfarlane", "funko pop", "marvel legends", "dc multiverse",
                    "star wars black series", "transformers", "gi joe", "power rangers", "tmnt",
                    "batman figure", "superman figure", "spider-man figure", "iron man figure", "joker figure",
                    "vintage figures", "loose figures", "mint on card", "moc", "mint in box", "mib"
                ]
            },
            
            "Fashion": {
                "Sneakers": [
                    # Jordan Brand (500+ variations)
                    "air jordan", "jordan 1", "jordan 4", "jordan 11", "jordan 3", "jordan 6", "jordan 12",
                    "chicago 1", "bred 4", "concord 11", "black cement 3", "infrared 6", "flu game 12",
                    "travis scott jordan", "off white jordan", "fragment jordan", "dior jordan",
                    "retro jordan", "og jordan", "high jordan", "low jordan", "mid jordan",
                    # Sizes
                    "size 8", "size 9", "size 10", "size 11", "size 12", "gs", "youth", "womens",
                    # Condition
                    "deadstock", "ds", "vnds", "used", "beater", "og all", "replacement box",
                    
                    # Nike (400+ variations)
                    "nike dunk", "dunk low", "dunk high", "sb dunk", "panda dunk", "michigan dunk",
                    "air force 1", "af1", "air max", "air max 90", "air max 97", "air max 270",
                    "blazer", "cortez", "react", "zoom", "pegasus", "vapormax", "presto",
                    
                    # Adidas (200+ variations)
                    "yeezy", "yeezy 350", "yeezy 700", "yeezy boost", "ultraboost", "nmd", "stan smith",
                    "gazelle", "campus", "samba", "forum", "superstar", "continental 80",
                    
                    # Other brands (150+ variations)
                    "new balance", "nb", "990", "991", "992", "993", "550", "2002r", "1906r",
                    "converse", "chuck taylor", "all star", "vans", "old skool", "authentic"
                ],
                
                "Streetwear": [
                    # Hypebeast brands (300+ variations)
                    "supreme", "off white", "fear of god", "essentials", "fog", "vetements", "balenciaga",
                    "stone island", "palace", "kith", "bape", "human made", "golf wang", "chrome hearts",
                    "gallery dept", "rhude", "amiri", "palm angels", "mastermind", "neighborhood",
                    # Items
                    "hoodie", "crewneck", "t-shirt", "sweatshirt", "jacket", "pants", "shorts", "hat"
                ]
            },
            
            "Vintage": {
                "Electronics": [
                    # Vintage Apple (200+ variations)
                    "vintage mac", "apple ii", "macintosh", "imac g3", "powerbook", "newton", "lisa",
                    "vintage iphone", "original iphone", "iphone 3g", "iphone 3gs", "iphone 4",
                    "vintage ipod", "ipod classic", "ipod mini", "ipod nano", "ipod shuffle", "ipod touch",
                    
                    # Gaming consoles (300+ variations)
                    "nintendo 64", "n64", "super nintendo", "snes", "nes", "gameboy", "game gear",
                    "sega genesis", "dreamcast", "saturn", "neo geo", "atari 2600", "colecovision",
                    "turbografx", "3do", "jaguar", "lynx", "wonderswan", "pc engine",
                    
                    # Audio equipment (200+ variations)
                    "vintage sony", "walkman", "discman", "boombox", "turntable", "technics 1200",
                    "vintage speakers", "jbl", "klipsch", "polk", "pioneer", "marantz", "mcintosh"
                ]
            }
        }
    
    def get_category_keywords(self, category: str, subcategory: str = None) -> List[str]:
        """Get keywords for category/subcategory with fallbacks"""
        if category not in self.keywords_db:
            return []
            
        if subcategory and subcategory in self.keywords_db[category]:
            return self.keywords_db[category][subcategory]
        
        # Return all keywords in category if no subcategory
        all_keywords = []
        for subcat_keywords in self.keywords_db[category].values():
            all_keywords.extend(subcat_keywords)
        return all_keywords
    
    def generate_keyword_variations(self, base_keyword: str, max_variations: int = 20) -> List[str]:
        """Generate comprehensive keyword variations"""
        variations = set([base_keyword.lower()])
        
        # Common substitution patterns
        substitutions = {
            'ph': 'f', 'f': 'ph', 'c': 'k', 'k': 'c', 's': 'z', 'z': 's',
            'tion': 'shun', 'ough': 'uff', 'ea': 'ee', 'ee': 'ea', 'ou': 'oo',
            'oo': 'ou', 'ai': 'ay', 'ay': 'ai', 'ei': 'ie', 'ie': 'ei'
        }
        
        # Apply substitutions
        for old, new in substitutions.items():
            if old in base_keyword.lower():
                variations.add(base_keyword.lower().replace(old, new))
        
        # Character-level variations
        word = base_keyword.lower()
        
        # Adjacent character swaps
        for i in range(len(word) - 1):
            swapped = list(word)
            swapped[i], swapped[i+1] = swapped[i+1], swapped[i]
            variations.add(''.join(swapped))
        
        # Missing characters
        for i in range(1, len(word) - 1):
            variations.add(word[:i] + word[i+1:])
        
        # Extra characters (common typos)
        common_extras = ['h', 'e', 's', 't', 'n', 'r', 'l']
        for i in range(len(word)):
            for char in common_extras:
                variations.add(word[:i] + char + word[i:])
        
        # Double letters
        for i in range(len(word)):
            if word[i].isalpha():
                variations.add(word[:i] + word[i] + word[i:])
        
        # Space variations
        variations.add(word.replace(' ', ''))
        variations.add(word.replace(' ', '-'))
        variations.add(word.replace(' ', '_'))
        
        # Number substitutions (leet speak)
        leet_map = {'o': '0', 'i': '1', 'e': '3', 'a': '@', 's': '$'}
        leet_word = word
        for letter, number in leet_map.items():
            leet_word = leet_word.replace(letter, number)
        if leet_word != word:
            variations.add(leet_word)
        
        # Plural/singular
        if word.endswith('s'):
            variations.add(word[:-1])
        else:
            variations.add(word + 's')
            variations.add(word + 'es')
        
        return list(variations)[:max_variations]
    
    def add_trending_keywords(self, keywords: List[str], priority: int = 1):
        """Add trending keywords to search queue"""
        for keyword in keywords:
            self.trending_queue.append({
                'keyword': keyword,
                'priority': priority,
                'added_date': datetime. in shipping_text:
                        shipping_match = re.search(r'\$?([\d,]+\.?\d*)', shipping_text)
                        if shipping_match:
                            shipping_cost = float(shipping_match.group(1).replace(',', ''))
                            break
            
            total_cost = price + shipping_cost
            
            # Enhanced link extraction
            link_selectors = [
                '.s-item__link',
                '.it-ttl a',
                '.s-item__title a',
                'a.s-item__link'
            ]
            
            ebay_link = ""
            for selector in link_selectors:
                link_elem = item_soup.select_one(selector)
                if link_elem:
                    href = link_elem.get('href', '')
                    if href:
                        # Clean the URL
                        ebay_link = href.split('?')[0] if '?' in href else href
                        break
            
            if not ebay_link:
                return None
            
            # Enhanced item ID extraction
            item_id_patterns = [
                r'/(\d{12,})',
                r'itm/(\d+)',
                r'item/(\d+)',
                r'/p/(\d+)'
            ]
            
            item_id = None
            for pattern in item_id_patterns:
                match = re.search(pattern, ebay_link)
                if match:
                    item_id = match.group(1)
                    break
            
            if not item_id:
                item_id = str(hash(title + str(price)))
            
            # Duplicate prevention
            if item_id in self.seen_items:
                return None
            self.seen_items.add(item_id)
            
            # Enhanced image extraction
            image_selectors = [
                '.s-item__image img',
                '.s-item__image',
                '.img img',
                'img[src*="ebayimg"]'
            ]
            
            image_url = ""
            for selector in image_selectors:
                img_elem = item_soup.select_one(selector)
                if img_elem:
                    image_url = img_elem.get('src', '') or img_elem.get('data-src', '')
                    if image_url:
                        # Clean image URL
                        image_url = image_url.replace('s-l64', 's-l500').replace('s-l140', 's-l500')
                        break
            
            # Enhanced condition extraction
            condition_selectors = [
                '.SECONDARY_INFO',
                '.s-item__subtitle',
                '.s-item__condition',
                '.s-item__detail--secondary'
            ]
            
            condition = "Unknown"
            for selector in condition_selectors:
                condition_elem = item_soup.select_one(selector)
                if condition_elem:
                    condition_text = condition_elem.get_text(strip=True)
                    # Clean condition text
                    condition_text = re.sub(r'\s+', ' ', condition_text)
                    if any(word in condition_text.lower() for word in ['new', 'used', 'refurbished', 'open box', 'certified']):
                        condition = condition_text
                        break
            
            # Enhanced seller information extraction
            seller_selectors = [
                '.s-item__seller-info-text',
                '.s-item__seller',
                '.mbg-nw',
                '.s-item__seller-info'
            ]
            
            seller_rating = "Not available"
            feedback_count = "Not available"
            
            for selector in seller_selectors:
                seller_elem = item_soup.select_one(selector)
                if seller_elem:
                    seller_text = seller_elem.get_text(strip=True)
                    # Extract rating percentage
                    rating_match = re.search(r'([\d.]+)%', seller_text)
                    if rating_match:
                        seller_rating = f"{rating_match.group(1)}%"
                    
                    # Extract feedback count
                    count_match = re.search(r'\(([\d,]+)\)', seller_text)
                    if count_match:
                        feedback_count = count_match.group(1).replace(',', '')
                    
                    if rating_match or count_match:
                        break
            
            # Location extraction
            location_selectors = [
                '.s-item__location',
                '.s-item__itemLocation',
                '.s-item__shipping'
            ]
            
            location = "Unknown"
            for selector in location_selectors:
                location_elem = item_soup.select_one(selector)
                if location_elem:
                    location_text = location_elem.get_text(strip=True)
                    if 'from' in location_text.lower():
                        location = location_text.replace('From', '').replace('from', '').strip()
                        break
                    elif any(word in location_text.lower() for word in ['usa', 'china', 'japan', 'uk', 'canada']):
                        location = location_text
                        break
            
            # Check if auction or Buy It Now
            is_auction = bool(item_soup.select_one('.s-item__time-left, .timeMs, .vi-time-left'))
            
            # Extract time left for auctions
            time_left = "Buy It Now"
            if is_auction:
                time_elem = item_soup.select_one('.s-item__time-left, .timeMs, .vi-time-left')
                if time_elem:
                    time_left = time_elem.get_text(strip=True)
            
            # Additional metrics (often not available in search results)
            views_count = "Not available"
            watchers_count = "Not available"
            sold_count = "Not available"
            availability = "Available"
            
            # Check sold listings count
            sold_elem = item_soup.select_one('.s-item__quantitySold, .vi-qtyS-sold')
            if sold_elem:
                sold_text = sold_elem.get_text(strip=True)
                sold_match = re.search(r'(\d+)', sold_text)
                if sold_match:
                    sold_count = sold_match.group(1)
            
            # Enhanced profitability calculations
            estimated_resale_price = self.calculate_enhanced_resale_price(
                title, price, condition, category, subcategory, location
            )
            estimated_profit = estimated_resale_price - total_cost
            profit_margin_percent = (estimated_profit / estimated_resale_price * 100) if estimated_resale_price > 0 else 0
            
            # Enhanced confidence scoring
            confidence_score = self.calculate_enhanced_confidence_score(
                title, price, condition, seller_rating, estimated_profit, 
                category, subcategory, matched_keyword, location, feedback_count
            )
            
            return eBayListing(
                title=title,
                price=price,
                shipping_cost=shipping_cost,
                total_cost=total_cost,
                estimated_resale_price=estimated_resale_price,
                estimated_profit=estimated_profit,
                profit_margin_percent=profit_margin_percent,
                confidence_score=confidence_score,
                condition=condition,
                seller_rating=seller_rating,
                seller_feedback_count=feedback_count,
                return_policy="30-day returns",  # Default - would need individual page scraping
                shipping_time="3-7 business days",  # Default - would need individual page scraping
                image_url=image_url,
                ebay_link=ebay_link,
                item_id=item_id,
                category=category,
                subcategory=subcategory,
                matched_keyword=matched_keyword,
                listing_date=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                views_count=views_count,
                watchers_count=watchers_count,
                is_auction=is_auction,
                buy_it_now_price=price if not is_auction else 0.0,
                time_left=time_left,
                location=location,
                sold_count=sold_count,
                availability=availability
            )
            
        except Exception as e:
            logger.error(f"Error extracting listing data: {e}")
            return None
    
    def calculate_enhanced_resale_price(self, title: str, current_price: float, 
                                      condition: str, category: str, subcategory: str, location: str) -> float:
        """Advanced resale price estimation with market intelligence"""
        base_multiplier = 1.4  # 40% base markup
        
        # Category-specific multipliers based on market analysis
        category_multipliers = {
            'Tech': 1.3,        # Fast-moving, competitive
            'Gaming': 1.5,      # High demand, limited supply
            'Collectibles': 2.2,# High markup potential
            'Fashion': 1.8,     # Brand value
            'Vintage': 2.5,     # Rarity premium
            'Antiques': 2.0     # Collector value
        }
        
        # Subcategory-specific adjustments
        subcategory_multipliers = {
            'Trading Cards': 2.8,
            'Sneakers': 2.0,
            'Consoles': 1.4,
            'Graphics Cards': 1.2,
            'Smartphones': 1.3,
            'Headphones': 1.6
        }
        
        # Apply category multiplier
        if category in category_multipliers:
            base_multiplier *= category_multipliers[category]
        
        # Apply subcategory multiplier
        if subcategory in subcategory_multipliers:
            base_multiplier *= subcategory_multipliers[subcategory]
        
        # Condition-based adjustments
        condition_multipliers = {
            'new': 1.6, 'brand new': 1.6, 'new with tags': 1.7,
            'like new': 1.4, 'mint': 1.5, 'near mint': 1.4,
            'very good': 1.3, 'excellent': 1.35,
            'good': 1.2, 'very fine': 1.25,
            'acceptable': 1.1, 'used': 1.15, 'fair': 1.05
        }
        
        condition_key = next(
            (k for k in condition_multipliers.keys() if k in condition.lower()), 
            'used'
        )
        base_multiplier *= condition_multipliers[condition_key]
        
        # High-demand keywords analysis
        demand_keywords = [
            'rare', 'limited', 'exclusive', 'vintage', 'first edition',
            'sealed', 'mint', 'deadstock', 'og', 'grail', 'holy grail',
            'prototype', 'sample', 'promo', 'one of one', '1/1',
            'psa 10', 'bgs 10', 'cgc 10', 'gem mint', 'black label'
        ]
        
        demand_boost = 1.0
        for keyword in demand_keywords:
            if keyword in title.lower():
                demand_boost += 0.15
        
        base_multiplier *= min(demand_boost, 2.0)  # Cap at 100% boost
        
        # Price range optimization (market sweet spots)
        if 10 <= current_price <= 50:
            base_multiplier *= 1.2  # High turnover range
        elif 50 <= current_price <= 200:
            base_multiplier *= 1.15  # Optimal range
        elif 200 <= current_price <= 500:
            base_multiplier *= 1.1   # Good range
        elif current_price > 1000:
            base_multiplier *= 0.9   # Harder to flip
        
        # Location-based adjustments
        if 'china' in location.lower() or 'hong kong' in location.lower():
            base_multiplier *= 1.3  # Import arbitrage opportunity
        elif 'japan' in location.lower():
            base_multiplier *= 1.4  # Premium for Japanese items
        
        # Brand recognition boost
        premium_brands = [
            'apple', 'nike', 'jordan', 'supreme', 'rolex', 'pokemon',
            'louis vuitton', 'gucci', 'chanel', 'hermes', 'patek philippe'
        ]
        
        for brand in premium_brands:
            if brand in title.lower():
                base_multiplier *= 1.2
                break
        
        return round(current_price * base_multiplier, 2)
    
    def calculate_enhanced_confidence_score(self, title: str, price: float, condition: str,
                                          seller_rating: str, estimated_profit: float,
                                          category: str, subcategory: str, matched_keyword: str,
                                          location: str, feedback_count: str) -> int:
        """Advanced confidence scoring with multiple factors"""
        score = 50  # Base score
        
        # Price range scoring (optimized for different categories)
        if category == 'Collectibles':
            if 50 <= price <= 500:
                score += 25
            elif 20 <= price <= 1000:
                score += 15
        elif category == 'Tech':
            if 30 <= price <= 300:
                score += 25
            elif 15 <= price <= 800:
                score += 15
        else:
            if 20 <= price <= 200:
                score += 25
            elif 10 <= price <= 500:
                score += 15
        
        # Condition scoring
        condition_scores = {
            'new': 30, 'brand new': 30, 'new with tags': 35,
            'mint': 28, 'near mint': 25, 'like new': 25,
            'very good': 20, 'excellent': 22, 'very fine': 20,
            'good': 15, 'acceptable': 10, 'used': 12, 'fair': 8
        }
        
        for cond, points in condition_scores.items():
            if cond in condition.lower():
                score += points
                break
        
        # Profit-based scoring with category adjustments
        profit_thresholds = {
            'Collectibles': [25, 50, 100, 200],
            'Tech': [15, 30, 60, 120],
            'Gaming': [20, 40, 80, 150],
            'Fashion': [30, 60, 120, 250]
        }
        
        thresholds = profit_thresholds.get(category, [15, 30, 60, 120])
        
        if estimated_profit >= thresholds[3]:
            score += 30
        elif estimated_profit >= thresholds[2]:
            score += 25
        elif estimated_profit >= thresholds[1]:
            score += 20
        elif estimated_profit >= thresholds[0]:
            score += 15
        elif estimated_profit >= 5:
            score += 5
        elif estimated_profit < 0:
            score -= 30
        
        # Seller quality scoring
        try:
            if '%' in seller_rating:
                rating_value = float(re.search(r'([\d.]+)', seller_rating).group(1))
                if rating_value >= 99.5:
                    score += 20
                elif rating_value >= 98.0:
                    score += 15
                elif rating_value >= 95.0:
                    score += 10
                elif rating_value >= 90.0:
                    score += 5
                elif rating_value < 85.0:
                    score -= 15
        except:
            pass
        
        # Feedback count scoring
        try:
            if feedback_count != "Not available":
                count = int(feedback_count.replace(',', ''))
                if count >= 10000:
                    score += 15
                elif count >= 1000:
                    score += 10
                elif count >= 100:
                    score += 5
                elif count < 10:
                    score -= 10
        except:
            pass
        
        # Title quality and keyword relevance
        title_words = len(title.split())
        if title_words >= 10:
            score += 15
        elif title_words >= 6:
            score += 10
        elif title_words >= 4:
            score += 5
        
        # Keyword matching accuracy
        keyword_similarity = difflib.SequenceMatcher(
            None, matched_keyword.lower(), title.lower()
        ).ratio()
        
        if keyword_similarity > 0.8:
            score += 20
        elif keyword_similarity > 0.6:
            score += 15
        elif keyword_similarity > 0.4:
            score += 10
        elif keyword_similarity < 0.2:
            score -= 10
        
        # Location-based adjustments
        if 'usa' in location.lower() or 'united states' in location.lower():
            score += 10
        elif 'china' in location.lower():
            score -= 5  # Longer shipping, potential issues
        
        # Category-specific bonuses
        high_confidence_categories = ['Collectibles', 'Fashion', 'Vintage']
        if category in high_confidence_categories:
            score += 10
        
        # Brand recognition bonus
        premium_indicators = [
            'authentic', 'genuine', 'original', 'official', 'licensed',
            'certificate', 'serial number', 'hologram', 'warranty'
        ]
        
        for indicator in premium_indicators:
            if indicator in title.lower():
                score += 5
                break
        
        return max(0, min(100, score))
    
    def scan_category_comprehensive(self, category: str, subcategory: str = None, 
                                  max_pages: int = 5, min_profit: float = 15.0) -> List[eBayListing]:
        """Comprehensive category scanning with parallel processing"""
        logger.info(f"🔍 Scanning {category}" + (f" > {subcategory}" if subcategory else ""))
        
        keywords = self.keyword_db.get_category_keywords(category, subcategory)
        if not keywords:
            logger.warning(f"❌ No keywords found for {category}/{subcategory}")
            return []
        
        all_listings = []
        self.session_stats['categories_searched'].add(f"{category}/{subcategory or 'All'}")
        
        # Prioritize keywords by search frequency and relevance
        priority_keywords = keywords[:10] if len(keywords) > 10 else keywords
        
        # Use ThreadPoolExecutor for parallel keyword processing
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_to_keyword = {}
            
            for keyword in priority_keywords:
                future = executor.submit(
                    self._process_keyword, keyword, category, subcategory, max_pages, min_profit
                )
                future_to_keyword[future] = keyword
            
            for future in as_completed(future_to_keyword):
                keyword = future_to_keyword[future]
                try:
                    keyword_listings = future.result()
                    all_listings.extend(keyword_listings)
                    logger.info(f"  ✅ '{keyword}': {len(keyword_listings)} profitable listings")
                except Exception as e:
                    logger.error(f"  ❌ '{keyword}' failed: {e}")
        
        return all_listings
    
    def _process_keyword(self, keyword: str, category: str, subcategory: str, 
                        max_pages: int, min_profit: float) -> List[eBayListing]:
        """Process a single keyword with variations"""
        keyword_listings = []
        self.session_stats['total_searches'] += 1
        
        # Generate and test keyword variations
        variations = self.keyword_db.generate_keyword_variations(keyword, 5)
        
        for variation in variations[:3]:  # Limit to top 3 variations
            for page in range(1, max_pages + 1):
                url = self.build_advanced_search_url(variation, page)
                soup = self.fetch_page_with_retry(url)
                
                if not soup:
                    break
                
                # Multiple item container selectors
                item_selectors = [
                    '.s-item__wrapper',
                    '.s-item',
                    '.srp-results .s-item',
                    '.srp-river-results .s-item'
                ]
                
                items = []
                for selector in item_selectors:
                    items = soup.select(selector)
                    if items:
                        break
                
                if not items:
                    break
                
                self.session_stats['total_listings_found'] += len(items)
                
                for item in items:
                    listing = self.extract_enhanced_listing_data(
                        item, category, subcategory or 'General', keyword
                    )
                    
                    if listing and listing.estimated_profit >= min_profit:
                        keyword_listings.append(listing)
                        self.session_stats['profitable_listings'] += 1
                
                # Smart rate limiting
                time.sleep(random.uniform(0.5, 2.0))
            
            # Delay between variations
            time.sleep(random.uniform(0.3, 1.0))
        
        return keyword_listings
    
    def comprehensive_arbitrage_scan(self, target_categories: List[str] = None, 
                                   target_subcategories: Dict[str, List[str]] = None,
                                   min_profit: float = 15.0, max_results: int = 50) -> Dict:
        """Main scanning function with comprehensive analysis"""
        logger.info("🚀 Starting comprehensive FlipHawk arbitrage scan...")
        
        # Reset session stats
        self.session_stats = {
            'total_searches': 0,
            'total_listings_found': 0,
            'profitable_listings': 0,
            'categories_searched': set(),
            'start_time': datetime.now(),
            'success_rate': 0.0
        }
        
        all_opportunities = []
        
        # Default categories if none specified
        if not target_categories:
            target_categories = ['Tech', 'Gaming', 'Collectibles']
        
        # Scan each category
        for category in target_categories:
            if category in self.keyword_db.keywords_db:
                subcategories_to_scan = []
                
                if target_subcategories and category in target_subcategories:
                    subcategories_to_scan = target_subcategories[category]
                else:
                    subcategories_to_scan = list(self.keyword_db.keywords_db[category].keys())
                
                # Limit subcategories for performance
                for subcategory in subcategories_to_scan[:3]:  # Max 3 subcategories per category
                    try:
                        category_listings = self.scan_category_comprehensive(
                            category, subcategory, max_pages=3, min_profit=min_profit
                        )
                        all_opportunities.extend(category_listings)
                        
                        # Break if we have enough results
                        if len(all_opportunities) >= max_results * 2:
                            break
                            
                    except Exception as e:
                        logger.error(f"Error scanning {category}/{subcategory}: {e}")
                        continue
        
        # Calculate success rate
        if self.session_stats['total_listings_found'] > 0:
            self.session_stats['success_rate'] = (
                self.session_stats['profitable_listings'] / 
                self.session_stats['total_listings_found'] * 100
            )
        
        # Rank and filter results
        ranked_opportunities = self.rank_arbitrage_opportunities(all_opportunities)
        top_opportunities = ranked_opportunities[:max_results]
        
        # Generate comprehensive summary
        end_time = datetime.now()
        duration = end_time - self.session_stats['start_time']
        
        summary = {
            'scan_metadata': {
                'scan_id': hashlib.md5(str(self.session_stats['start_time']).encode()).hexdigest()[:8],
                'timestamp': end_time.isoformat(),
                'duration_seconds': round(duration.total_seconds(), 2),
                'total_searches_performed': self.session_stats['total_searches'],
                'total_listings_analyzed': self.session_stats['total_listings_found'],
                'profitable_listings_found': len(all_opportunities),
                'categories_scanned': list(self.session_stats['categories_searched']),
                'scan_efficiency': round(self.session_stats['success_rate'], 2),
                'average_listings_per_search': round(
                    self.session_stats['total_listings_found'] / 
                    max(self.session_stats['total_searches'], 1), 2
                )
            },
            'opportunities_summary': {
                'total_opportunities': len(top_opportunities),
                'average_profit': round(
                    sum(op.estimated_profit for op in top_opportunities) / 
                    len(top_opportunities), 2
                ) if top_opportunities else 0,
                'average_confidence': round(
                    sum(op.confidence_score for op in top_opportunities) / 
                    len(top_opportunities), 1
                ) if top_opportunities else 0,
                'highest_profit': max(
                    (op.estimated_profit for op in top_opportunities), default=0
                ),
                'lowest_profit': min(
                    (op.estimated_profit for op in top_opportunities), default=0
                ),
                'categories_represented': list(set(op.category for op in top_opportunities)),
                'subcategories_represented': list(set(op.subcategory for op in top_opportunities)),
                'profit_ranges': {
                    'under_25': len([op for op in top_opportunities if op.estimated_profit < 25]),
                    '25_to_50': len([op for op in top_opportunities if 25 <= op.estimated_profit < 50]),
                    '50_to_100': len([op for op in top_opportunities if 50 <= op.estimated_profit < 100]),
                    'over_100': len([op for op in top_opportunities if op.estimated_profit >= 100])
                }
            },
            'top_opportunities': [asdict(listing) for listing in top_opportunities],
            'performance_metrics': {
                'listings_per_second': round(
                    self.session_stats['total_listings_found'] / 
                    max(duration.total_seconds(), 1), 2
                ),
                'profitable_percentage': round(self.session_stats['success_rate'], 2),
                'categories_per_minute': round(
                    len(self.session_stats['categories_searched']) / 
                    max(duration.total_seconds() / 60, 1), 2
                )
            }
        }
        
        logger.info(f"✅ Scan completed: {len(top_opportunities)} opportunities found")
        return summary
    
    def rank_arbitrage_opportunities(self, opportunities: List[eBayListing]) -> List[eBayListing]:
        """Advanced ranking algorithm with multiple factors"""
        def calculate_opportunity_score(listing):
            # Weighted scoring algorithm
            profit_score = min(listing.estimated_profit / 300, 1.0) * 0.30  # 30% weight
            confidence_score = listing.confidence_score / 100 * 0.25  # 25% weight
            margin_score = min(listing.profit_margin_percent / 100, 1.0) * 0.20  # 20% weight
            
            # Price range optimization (15% weight)
            price_score = 0.0
            if 20 <= listing.total_cost <= 150:
                price_score = 0.15
            elif 10 <= listing.total_cost <= 300:
                price_score = 0.10
            elif 5 <= listing.total_cost <= 500:
                price_score = 0.05
            
            # Category and condition bonus (10% weight)
            category_bonus = 0.0
            high_opportunity_categories = ['Collectibles', 'Fashion', 'Gaming', 'Vintage']
            if listing.category in high_opportunity_categories:
                category_bonus += 0.05
            
            if 'new' in listing.condition.lower() or 'mint' in listing.condition.lower():
                category_bonus += 0.05
            
            return profit_score + confidence_score + margin_score + price_score + category_bonus
        
        return sorted(opportunities, key=calculate_opportunity_score, reverse=True)

# Flask Integration Functions
def create_api_endpoints(scraper: EnhancedFlipHawkScraper):
    """Create Flask-compatible API endpoint functions"""
    
    def scan_arbitrage_opportunities(request_data: Dict) -> Dict:
        """Main API endpoint for arbitrage scanning"""
        try:
            target_categories = request_data.get('categories', ['Tech', 'Gaming', 'Collectibles'])
            target_subcategories = request_data.get('subcategories', {})
            min_profit = float(request_data.get('min_profit', 15.0))
            max_results = int(request_data.get('max_results', 25))
            
            results = scraper.comprehensive_arbitrage_scan(
                target_categories=target_categories,
                target_subcategories=target_subcategories,
                min_profit=min_profit,
                max_results=max_results
            )
            
            return {
                'status': 'success',
                'data': results,
                'message': 'Arbitrage scan completed successfully'
            }
            
        except Exception as e:
            logger.error(f"Scan failed: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'data': None
            }
    
    def add_trending_keywords_endpoint(request_data: Dict) -> Dict:
        """API endpoint to add trending keywords"""
        try:
            keywords_list = request_data.get('keywords', [])
            priority = int(request_data.get('priority', 1))
            
            scraper.keyword_db.add_trending_keywords(keywords_list, priority)
            
            return {
                'status': 'success',
                'message': f'Added {len(keywords_list)} trending keywords',
                'data': {'keywords_added': keywords_list}
            }
            
        except Exception as e:
            logger.error(f"Failed to add trending keywords: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'data': None
            }
    
    def get_categories_endpoint() -> Dict:
        """API endpoint to get available categories and subcategories"""
        try:
            categories_data = {}
            for category, subcategories in scraper.keyword_db.keywords_db.items():
                categories_data[category] = {
                    'subcategories': list(subcategories.keys()),
                    'total_keywords': sum(len(keywords) for keywords in subcategories.values()),
                    'description': f"{category} products and accessories"
                }
            
            return {
                'status': 'success',
                'data': categories_data,
                'message': 'Categories retrieved successfully'
            }
            
        except Exception as e:
            logger.error(f"Failed to get categories: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'data': None
            }
    
    def get_session_stats_endpoint() -> Dict:
        """API endpoint to get current session statistics"""
        try:
            stats = scraper.session_stats.copy()
            stats['categories_searched'] = list(stats['categories_searched'])
            stats['uptime_seconds'] = (datetime.now() - stats['start_time']).total_seconds()
            
            return {
                'status': 'success',
                'data': stats,
                'message': 'Session stats retrieved successfully'
            }
            
        except Exception as e:
            logger.error(f"Failed to get session stats: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'data': None
            }
    
    return {
        'scan_arbitrage': scan_arbitrage_opportunities,
        'add_trending': add_trending_keywords_endpoint,
        'get_categories': get_categories_endpoint,
        'get_session_stats': get_session_stats_endpoint
    }

# Utility Functions
def validate_scan_request(request_data: Dict) -> Dict:
    """Validate incoming scan request data"""
    errors = []
    
    # Validate categories
    valid_categories = ['Tech', 'Gaming', 'Collectibles', 'Fashion', 'Vintage', 'Antiques']
    categories = request_data.get('categories', [])
    
    if not isinstance(categories, list):
        errors.append("Categories must be a list")
    elif not all(cat in valid_categories for cat in categories):
        errors.append(f"Invalid categories. Valid options: {valid_categories}")
    
    # Validate min_profit
    try:
        min_profit = float(request_data.get('min_profit', 15.0))
        if min_profit < 0 or min_profit > 1000:
            errors.append("Min profit must be between 0 and 1000")
    except ValueError:
        errors.append("Min profit must be a valid number")
    
    # Validate max_results
    try:
        max_results = int(request_data.get('max_results', 25))
        if max_results < 1 or max_results > 100:
            errors.append("Max results must be between 1 and 100")
    except ValueError:
        errors.append("Max results must be a valid integer")
    
    return {
        'valid': len(errors) == 0,
        'errors': errors
    }

# Demo and Testing Functions
def demo_scraper():
    """Demonstration function for testing the scraper"""
    scraper = EnhancedFlipHawkScraper()
    
    # Add some trending keywords
    trending_keywords = [
        "mini washing machine", "led strip lights", "phone camera lens",
        "bluetooth speaker", "wireless charging pad", "airpods pro 2",
        "nintendo switch oled", "pokemon cards booster box"
    ]
    scraper.keyword_db.add_trending_keywords(trending_keywords, priority=1)
    
    # Test scan
    print("🚀 Starting demo scan...")
    results = scraper.comprehensive_arbitrage_scan(
        target_categories=['Tech'],
        target_subcategories={'Tech': ['Headphones', 'Smartphones']},
        min_profit=20.0,
        max_results=5
    )
    
    # Display results
    print(f"\n📊 DEMO RESULTS:")
    print(f"Duration: {results['scan_metadata']['duration_seconds']} seconds")
    print(f"Opportunities: {results['opportunities_summary']['total_opportunities']}")
    print(f"Average profit: ${results['opportunities_summary']['average_profit']}")
    print(f"Success rate: {results['scan_metadata']['scan_efficiency']}%")
    
    if results['top_opportunities']:
        print(f"\n🏆 TOP OPPORTUNITY:")
        top = results['top_opportunities'][0]
        print(f"Title: {top['title'][:60]}...")
        print(f"Profit: ${top['estimated_profit']:.2f}")
        print(f"Confidence: {top['confidence_score']}%")
        print(f"Link: {top['ebay_link']}")
    
    return results

if __name__ == "__main__":
    # Run demo
    demo_scraper()"""
FlipHawk Enhanced eBay Scraper
Production-ready scraper with comprehensive keyword database and intelligent analysis
"""

import urllib.request
import urllib.parse
from bs4 import BeautifulSoup
import json
import re
import time
import random
from typing import List, Dict, Optional, Set, Tuple
import hashlib
from dataclasses import dataclass, asdict
from collections import defaultdict
from datetime import datetime, timedelta
import difflib
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import os

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class eBayListing:
    """Enhanced eBay listing data structure"""
    title: str
    price: float
    shipping_cost: float
    total_cost: float
    estimated_resale_price: float
    estimated_profit: float
    profit_margin_percent: float
    confidence_score: int
    condition: str
    seller_rating: str
    seller_feedback_count: str
    return_policy: str
    shipping_time: str
    image_url: str
    ebay_link: str
    item_id: str
    category: str
    subcategory: str
    matched_keyword: str
    listing_date: str
    views_count: str
    watchers_count: str
    is_auction: bool
    buy_it_now_price: float
    time_left: str
    location: str
    sold_count: str
    availability: str

class KeywordDatabase:
    """Manages comprehensive keyword database with 10,000+ variations"""
    
    def __init__(self):
        self.keywords_db = self._load_comprehensive_keywords()
        self.trending_queue = []
        self.search_history = defaultdict(int)
        
    def _load_comprehensive_keywords(self):
        """Load massive keyword database organized by categories"""
        return {
            "Tech": {
                "Headphones": [
                    # Apple AirPods ecosystem (200+ variations)
                    "airpods", "airpod", "air pods", "air pod", "apple earbuds", "apple earpods",
                    "airpods pro", "airpods max", "airpods 2", "airpods 3", "airpods pro 2", "airpods gen 2", "airpods gen 3",
                    "airpods 2nd generation", "airpods 3rd generation", "airpods pro 2nd generation", "airpods magsafe",
                    "airpods lightning", "airpods usb-c", "airpods wireless", "airpods noise cancelling",
                    # Common typos and misspellings
                    "airpds", "aripos", "aripods", "apods", "ap pods", "apple airpads", "air buds", "earbuds apple",
                    "airpods pro max", "apple airpod pro", "airpods noise", "airpods anc", "airpod case",
                    
                    # Beats ecosystem (150+ variations)
                    "beats", "beats headphones", "beats solo", "beats studio", "beats pro", "beats wireless",
                    "beats solo 3", "beats solo3", "beats studio 3", "beats studio3", "beats studio buds",
                    "beats fit pro", "powerbeats", "powerbeats pro", "beats x", "beatsx", "urbeats",
                    "beats ep", "beats mixr", "beats executive", "beats tour", "beats in ear",
                    # Typos
                    "beets", "bats headphones", "beatz", "beat headphones", "beats dr dre", "dre beats",
                    
                    # Bose ecosystem (100+ variations)
                    "bose", "bose headphones", "bose quietcomfort", "bose qc", "bose nc", "bose earbuds",
                    "bose qc35", "bose qc45", "bose qc25", "bose 700", "bose nc 700", "bose soundsport",
                    "bose quietcomfort 35", "bose quietcomfort 45", "bose sport earbuds", "bose sleepbuds",
                    "bose around ear", "bose on ear", "bose in ear", "bose wireless", "bose bluetooth",
                    # Typos
                    "boss headphones", "boze", "bosee", "quiet comfort", "bose 35 ii", "bose qc 45",
                    
                    # Sony ecosystem (120+ variations)
                    "sony wh", "sony wf", "sony headphones", "sony earbuds", "sony xm4", "sony xm5", "sony xm3",
                    "sony wh-1000xm4", "sony wh-1000xm5", "sony wh-1000xm3", "sony wf-1000xm4", "sony wf-1000xm5",
                    "sony wh1000xm4", "sony wf1000xm4", "sony linkbuds", "sony extra bass", "sony xb",
                    "sony wh-ch710n", "sony wh-ch720n", "sony wh-xb900n", "sony mdr", "sony walkman",
                    # Typos
                    "sonny headphones", "soney", "sony x1000", "sony 1000xm4", "sony noise cancel",
                    
                    # Gaming headsets (80+ variations)
                    "gaming headset", "gaming headphones", "pc gaming headset", "xbox headset", "ps5 headset",
                    "steelseries arctis", "hyperx cloud", "razer kraken", "logitech g pro", "corsair void",
                    "turtle beach", "astro a40", "astro a50", "sennheiser game", "audio technica gaming",
                    
                    # General audio terms (100+ variations)
                    "wireless headphones", "bluetooth headphones", "bluetooth earbuds", "true wireless",
                    "noise cancelling headphones", "anc headphones", "over ear headphones", "on ear headphones",
                    "in ear headphones", "studio headphones", "monitor headphones", "reference headphones",
                    "hi-fi headphones", "audiophile headphones", "open back headphones", "closed back headphones"
                ],
                
                "Smartphones": [
                    # iPhone ecosystem (300+ variations)
                    "iphone", "iphone 15", "iphone 15 pro", "iphone 15 pro max", "iphone 15 plus",
                    "iphone 14", "iphone 14 pro", "iphone 14 pro max", "iphone 14 plus", "iphone 13",
                    "iphone 13 pro", "iphone 13 pro max", "iphone 13 mini", "iphone 12", "iphone 12 pro",
                    "iphone 12 pro max", "iphone 12 mini", "iphone 11", "iphone 11 pro", "iphone 11 pro max",
                    "iphone se", "iphone se 2022", "iphone se 3rd generation", "iphone xr", "iphone xs",
                    # Colors and storage
                    "iphone black", "iphone white", "iphone blue", "iphone red", "iphone purple", "iphone pink",
                    "iphone 128gb", "iphone 256gb", "iphone 512gb", "iphone 1tb", "iphone unlocked",
                    "iphone verizon", "iphone att", "iphone t-mobile", "iphone sprint",
                    # Typos
                    "ifone", "i phone", "apple phone", "iphone pro max", "iph0ne", "iphome",
                    
                    # Samsung Galaxy ecosystem (200+ variations)
                    "samsung galaxy", "galaxy s24", "galaxy s23", "galaxy s22", "galaxy s21", "galaxy s20",
                    "galaxy s24 ultra", "galaxy s23 ultra", "galaxy s22 ultra", "galaxy s21 ultra",
                    "galaxy s24 plus", "galaxy s23 plus", "galaxy note", "galaxy note 20", "galaxy fold",
                    "galaxy z fold", "galaxy z flip", "galaxy a54", "galaxy a53", "galaxy a52", "galaxy a51",
                    "samsung s24", "samsung s23", "samsung phone", "galaxy phone", "samsung android",
                    # Typos
                    "samung", "samsung galxy", "galxy", "samsung galaxy s", "note ultra",
                    
                    # Google Pixel ecosystem (100+ variations)
                    "google pixel", "pixel 8", "pixel 8 pro", "pixel 7", "pixel 7 pro", "pixel 7a",
                    "pixel 6", "pixel 6 pro", "pixel 6a", "pixel 5", "pixel 4", "pixel 4a",
                    "pixel phone", "google phone", "pixel android", "pixel camera", "pixel unlocked",
                    
                    # Other Android brands (150+ variations)
                    "oneplus", "oneplus 12", "oneplus 11", "oneplus nord", "xiaomi", "redmi", "poco",
                    "huawei", "honor", "oppo", "vivo", "realme", "motorola", "moto g", "nothing phone"
                ],
                
                "Laptops": [
                    # MacBook ecosystem (200+ variations)
                    "macbook", "macbook pro", "macbook air", "mac book", "macbook m3", "macbook m2", "macbook m1",
                    "macbook pro 16", "macbook pro 14", "macbook pro 13", "macbook air 15", "macbook air 13",
                    "macbook pro m3", "macbook pro m2", "macbook pro m1", "macbook air m3", "macbook air m2",
                    "macbook 2024", "macbook 2023", "macbook 2022", "macbook 2021", "macbook space gray",
                    "macbook silver", "macbook midnight", "macbook starlight", "apple laptop", "mac laptop",
                    # Storage and specs
                    "macbook 256gb", "macbook 512gb", "macbook 1tb", "macbook 8gb", "macbook 16gb", "macbook 32gb",
                    # Typos
                    "mackbook", "macbok", "mac book pro", "apple macbook", "macbook retina",
                    
                    # Gaming laptops (300+ variations)
                    "gaming laptop", "rog laptop", "asus rog", "legion laptop", "msi gaming", "alienware",
                    "razer blade", "predator laptop", "hp omen", "dell g15", "nitro 5", "tuf gaming",
                    "rog strix", "rog zephyrus", "legion 5", "legion 7", "msi katana", "msi stealth",
                    "alienware m15", "alienware x14", "razer blade 15", "razer blade 14", "predator helios",
                    # GPU specs
                    "rtx 4090 laptop", "rtx 4080 laptop", "rtx 4070 laptop", "rtx 4060 laptop", "rtx 3080 laptop",
                    "gaming laptop 144hz", "gaming laptop 240hz", "gaming notebook", "high refresh laptop",
                    
                    # Business laptops (200+ variations)
                    "thinkpad", "dell xps", "hp elitebook", "surface laptop", "business laptop", "ultrabook",
                    "thinkpad x1", "thinkpad carbon", "thinkpad t14", "thinkpad p1", "dell xps 13", "dell xps 15",
                    "surface laptop 5", "surface book", "hp spectre", "hp envy", "lenovo yoga", "2-in-1 laptop"
                ],
                
                "Graphics Cards": [
                    # NVIDIA RTX 40 series (150+ variations)
                    "rtx 4090", "rtx 4080", "rtx 4070", "rtx 4060", "rtx 4070 ti", "rtx 4060 ti",
                    "geforce rtx 4090", "nvidia rtx 4090", "rtx 4090 24gb", "rtx 4080 16gb", "rtx 4070 12gb",
                    "rtx 4090 founders edition", "rtx 4080 fe", "rtx 4070 ti super", "rtx 4060 8gb",
                    
                    # NVIDIA RTX 30 series (200+ variations)
                    "rtx 3090", "rtx 3080", "rtx 3070", "rtx 3060", "rtx 3050", "rtx 3090 ti", "rtx 3080 ti",
                    "rtx 3070 ti", "rtx 3060 ti", "rtx 3090 24gb", "rtx 3080 10gb", "rtx 3080 12gb",
                    "rtx 3070 8gb", "rtx 3060 12gb", "rtx 3060 8gb", "rtx 3050 8gb",
                    
                    # AMD Radeon (150+ variations)
                    "rx 7900 xtx", "rx 7900 xt", "rx 7800 xt", "rx 7700 xt", "rx 7600", "rx 6950 xt",
                    "rx 6900 xt", "rx 6800 xt", "rx 6800", "rx 6750 xt", "rx 6700 xt", "rx 6650 xt",
                    "rx 6600 xt", "rx 6600", "rx 6500 xt", "radeon rx", "amd radeon", "amd gpu",
                    
                    # Brands and terms (100+ variations)
                    "asus gpu", "msi gpu", "gigabyte gpu", "evga gpu", "zotac gpu", "founders edition",
                    "graphics card", "video card", "gpu", "gaming gpu", "mining gpu", "ai gpu"
                ]
            },
            
            "Gaming": {
                "Consoles": [
                    # PlayStation ecosystem (200+ variations)
                    "playstation 5", "ps5", "ps5 console", "ps5 disc", "ps5 digital", "playstation 5 digital",
                    "ps5 bundle", "ps5 controller", "ps5 games", "ps5 headset", "ps5 pro", "ps5 slim",
                    "playstation 4", "ps4", "ps4 pro", "ps4 slim", "ps4 console", "ps4 bundle",
                    "ps vita", "psp", "playstation portable", "playstation classic",
                    # Typos
                    "playstaton", "play station", "ps 5", "playstation5", "ps5 disk",
                    
                    # Xbox ecosystem (150+ variations)
                    "xbox series x", "xbox series s", "xbox sx", "xbox ss", "xbox series", "xbox console",
                    "xbox one", "xbox one x", "xbox one s", "xbox 360", "xbox original", "xbox controller",
                    "xbox gamepass", "xbox live", "xbox elite controller", "xbox wireless controller",
                    # Typos
                    "x box", "xobx", "xbox seriex x", "xbox series", "microsoft xbox",
                    
                    # Nintendo ecosystem (200+ variations)
                    "nintendo switch", "switch oled", "switch lite", "nintendo switch oled", "switch console",
                    "switch pro controller", "switch games", "joy con", "joycon", "switch dock",
                    "nintendo 3ds", "3ds xl", "2ds", "nintendo ds", "gameboy", "wii", "wii u",
                    # Typos
                    "nintedo", "nintndo", "switch lite", "nintendo swich", "joy-con"
                ],
                
                "Video Games": [
                    # Popular franchises (500+ variations)
                    "call of duty", "cod", "modern warfare", "warzone", "black ops", "battlefield",
                    "fifa 24", "madden 24", "nba 2k24", "grand theft auto", "gta", "red dead redemption",
                    "elder scrolls", "skyrim", "fallout", "witcher 3", "cyberpunk 2077", "assassins creed",
                    "spider-man", "spider man", "god of war", "last of us", "uncharted", "horizon",
                    "zelda", "breath of the wild", "tears of kingdom", "mario", "pokemon", "final fantasy",
                    # Platform specific
                    "ps5 games", "xbox games", "nintendo switch games", "pc games", "steam games",
                    # Conditions and types
                    "sealed games", "new games", "used games", "collectors edition", "limited edition"
                ]
            },
            
            "Collectibles": {
                "Trading Cards": [
                    # Pokemon TCG (400+ variations)
                    "pokemon cards", "pokemon tcg", "pokemon booster", "pokemon packs", "pokemon box",
                    "charizard", "pikachu", "blastoise", "venusaur", "mewtwo", "mew", "lugia", "rayquaza",
                    "base set", "shadowless", "first edition", "1st edition", "unlimited", "japanese pokemon",
                    "psa 10", "psa 9", "bgs 10", "cgc 10", "graded pokemon", "mint pokemon", "gem mint",
                    "pokemon booster box", "pokemon etb", "elite trainer box", "pokemon tin", "pokemon collection",
                    # Sets
                    "scarlet violet", "paldea evolved", "obsidian flames", "151", "classic collection",
                    "brilliant stars", "evolving skies", "chilling reign", "battle styles", "shining fates",
                    # Typos
                    "pokémon", "pokemom", "pokmon", "pokemon card", "charizrd", "pickachu",
                    
                    # Magic: The Gathering (300+ variations)
                    "magic the gathering", "mtg", "mtg cards", "magic cards", "mtg booster", "commander deck",
                    "black lotus", "mox", "dual lands", "fetch lands", "shock lands", "planeswalker",
                    "alpha mtg", "beta mtg", "power nine", "reserve list", "vintage mtg", "legacy mtg",
                    "modern horizons", "dominaria", "innistrad", "ravnica", "zendikar", "phyrexia",
                    # Formats
                    "commander", "edh", "standard", "modern", "legacy", "vintage", "pioneer",
                    
                    # Sports Cards (200+ variations)
                    "basketball cards", "nba cards", "football cards", "nfl cards", "baseball cards",
                    "mlb cards", "soccer cards", "topps", "panini", "upper deck", "prizm", "select",
                    "rookie cards", "autograph cards", "jersey cards", "patch cards", "graded cards",
                    "michael jordan", "lebron james", "tom brady", "patrick mahomes", "mike trout"
                ],
                
                "Action Figures": [
                    # Popular lines (300+ variations)
                    "hot toys", "sideshow", "neca", "mcfarlane", "funko pop", "marvel legends", "dc multiverse",
                    "star wars black series", "transformers", "gi joe", "power rangers", "tmnt",
                    "batman figure", "superman figure", "spider-man figure", "iron man figure", "joker figure",
                    "vintage figures", "loose figures", "mint on card", "moc", "mint in box", "mib"
                ]
            },
            
            "Fashion": {
                "Sneakers": [
                    # Jordan Brand (500+ variations)
                    "air jordan", "jordan 1", "jordan 4", "jordan 11", "jordan 3", "jordan 6", "jordan 12",
                    "chicago 1", "bred 4", "concord 11", "black cement 3", "infrared 6", "flu game 12",
                    "travis scott jordan", "off white jordan", "fragment jordan", "dior jordan",
                    "retro jordan", "og jordan", "high jordan", "low jordan", "mid jordan",
                    # Sizes
                    "size 8", "size 9", "size 10", "size 11", "size 12", "gs", "youth", "womens",
                    # Condition
                    "deadstock", "ds", "vnds", "used", "beater", "og all", "replacement box",
                    
                    # Nike (400+ variations)
                    "nike dunk", "dunk low", "dunk high", "sb dunk", "panda dunk", "michigan dunk",
                    "air force 1", "af1", "air max", "air max 90", "air max 97", "air max 270",
                    "blazer", "cortez", "react", "zoom", "pegasus", "vapormax", "presto",
                    
                    # Adidas (200+ variations)
                    "yeezy", "yeezy 350", "yeezy 700", "yeezy boost", "ultraboost", "nmd", "stan smith",
                    "gazelle", "campus", "samba", "forum", "superstar", "continental 80",
                    
                    # Other brands (150+ variations)
                    "new balance", "nb", "990", "991", "992", "993", "550", "2002r", "1906r",
                    "converse", "chuck taylor", "all star", "vans", "old skool", "authentic"
                ],
                
                "Streetwear": [
                    # Hypebeast brands (300+ variations)
                    "supreme", "off white", "fear of god", "essentials", "fog", "vetements", "balenciaga",
                    "stone island", "palace", "kith", "bape", "human made", "golf wang", "chrome hearts",
                    "gallery dept", "rhude", "amiri", "palm angels", "mastermind", "neighborhood",
                    # Items
                    "hoodie", "crewneck", "t-shirt", "sweatshirt", "jacket", "pants", "shorts", "hat"
                ]
            },
            
            "Vintage": {
                "Electronics": [
                    # Vintage Apple (200+ variations)
                    "vintage mac", "apple ii", "macintosh", "imac g3", "powerbook", "newton", "lisa",
                    "vintage iphone", "original iphone", "iphone 3g", "iphone 3gs", "iphone 4",
                    "vintage ipod", "ipod classic", "ipod mini", "ipod nano", "ipod shuffle", "ipod touch",
                    
                    # Gaming consoles (300+ variations)
                    "nintendo 64", "n64", "super nintendo", "snes", "nes", "gameboy", "game gear",
                    "sega genesis", "dreamcast", "saturn", "neo geo", "atari 2600", "colecovision",
                    "turbografx", "3do", "jaguar", "lynx", "wonderswan", "pc engine",
                    
                    # Audio equipment (200+ variations)
                    "vintage sony", "walkman", "discman", "boombox", "turntable", "technics 1200",
                    "vintage speakers", "jbl", "klipsch", "polk", "pioneer", "marantz", "mcintosh"
                ]
            }
        }
    
    def get_category_keywords(self, category: str, subcategory: str = None) -> List[str]:
        """Get keywords for category/subcategory with fallbacks"""
        if category not in self.keywords_db:
            return []
            
        if subcategory and subcategory in self.keywords_db[category]:
            return self.keywords_db[category][subcategory]
        
        # Return all keywords in category if no subcategory
        all_keywords = []
        for subcat_keywords in self.keywords_db[category].values():
            all_keywords.extend(subcat_keywords)
        return all_keywords
    
    def generate_keyword_variations(self, base_keyword: str, max_variations: int = 20) -> List[str]:
        """Generate comprehensive keyword variations"""
        variations = set([base_keyword.lower()])
        
        # Common substitution patterns
        substitutions = {
            'ph': 'f', 'f': 'ph', 'c': 'k', 'k': 'c', 's': 'z', 'z': 's',
            'tion': 'shun', 'ough': 'uff', 'ea': 'ee', 'ee': 'ea', 'ou': 'oo',
            'oo': 'ou', 'ai': 'ay', 'ay': 'ai', 'ei': 'ie', 'ie': 'ei'
        }
        
        # Apply substitutions
        for old, new in substitutions.items():
            if old in base_keyword.lower():
                variations.add(base_keyword.lower().replace(old, new))
        
        # Character-level variations
        word = base_keyword.lower()
        
        # Adjacent character swaps
        for i in range(len(word) - 1):
            swapped = list(word)
            swapped[i], swapped[i+1] = swapped[i+1], swapped[i]
            variations.add(''.join(swapped))
        
        # Missing characters
        for i in range(1, len(word) - 1):
            variations.add(word[:i] + word[i+1:])
        
        # Extra characters (common typos)
        common_extras = ['h', 'e', 's', 't', 'n', 'r', 'l']
        for i in range(len(word)):
            for char in common_extras:
                variations.add(word[:i] + char + word[i:])
        
        # Double letters
        for i in range(len(word)):
            if word[i].isalpha():
                variations.add(word[:i] + word[i] + word[i:])
        
        # Space variations
        variations.add(word.replace(' ', ''))
        variations.add(word.replace(' ', '-'))
        variations.add(word.replace(' ', '_'))
        
        # Number substitutions (leet speak)
        leet_map = {'o': '0', 'i': '1', 'e': '3', 'a': '@', 's': '$'}
        leet_word = word
        for letter, number in leet_map.items():
            leet_word = leet_word.replace(letter, number)
        if leet_word != word:
            variations.add(leet_word)
        
        # Plural/singular
        if word.endswith('s'):
            variations.add(word[:-1])
        else:
            variations.add(word + 's')
            variations.add(word + 'es')
        
        return list(variations)[:max_variations]
    
    def add_trending_keywords(self, keywords: List[str], priority: int = 1):
        """Add trending keywords to search queue"""
        for keyword in keywords:
            self.trending_queue.append({
                'keyword': keyword,
                'priority': priority,
                'added_date': datetime.
